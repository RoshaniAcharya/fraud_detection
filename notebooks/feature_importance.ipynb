{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "102f4fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from geopy.distance import great_circle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, SelectFromModel, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PowerTransformer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86a79063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1296675, 23)\n",
      "Unnamed: 0                 int64\n",
      "trans_date_trans_time     object\n",
      "cc_num                     int64\n",
      "merchant                  object\n",
      "category                  object\n",
      "amt                      float64\n",
      "first                     object\n",
      "last                      object\n",
      "gender                    object\n",
      "street                    object\n",
      "city                      object\n",
      "state                     object\n",
      "zip                        int64\n",
      "lat                      float64\n",
      "long                     float64\n",
      "city_pop                   int64\n",
      "job                       object\n",
      "dob                       object\n",
      "trans_num                 object\n",
      "unix_time                  int64\n",
      "merch_lat                float64\n",
      "merch_long               float64\n",
      "is_fraud                   int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/home/fm-pc-lt-173/fraud_detection/pythonProject/data/fraudTrain.csv')\n",
    "print(df.shape)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b400051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "df['dob'] = pd.to_datetime(df['dob'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577e221d",
   "metadata": {},
   "source": [
    "**<h2>Training Decision Tree using the features to generate feature importance.</h2>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ca3466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data():\n",
    "    numerical_features = ['amt', 'lat', 'long', 'city_pop', 'unix_time', 'merch_lat', 'merch_long','cc_num']\n",
    "    categorical_features = ['merchant', 'category', 'first', 'last', 'gender', 'street', 'city', 'state', 'zip', 'job', 'trans_num']\n",
    "    numerical_transformer = StandardScaler()\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d286be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    257815\n",
      "           1       0.79      0.68      0.73      1520\n",
      "\n",
      "    accuracy                           1.00    259335\n",
      "   macro avg       0.89      0.84      0.86    259335\n",
      "weighted avg       1.00      1.00      1.00    259335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define features and target\n",
    "X = df.drop('is_fraud', axis=1)\n",
    "y = df['is_fraud']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "preprocessor = preprocess_data()\n",
    "\n",
    "print(\"here\")\n",
    "# Create the pipeline\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Save pipeline (including preprocessor and classifier) to a file\n",
    "# joblib.dump(clf, 'pipeline_with_model.joblib')\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d39080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of the numerical features\n",
    "numerical_features = ['amt', 'lat', 'long', 'city_pop', 'unix_time', 'merch_lat', 'merch_long']\n",
    "\n",
    "# Get the names of the categorical features after one-hot encoding\n",
    "categorical_transformer = clf.named_steps['preprocessor'].named_transformers_['cat']\n",
    "categorical_feature_names = categorical_transformer.get_feature_names_out(categorical_features)\n",
    "\n",
    "# Combine the names\n",
    "feature_names = list(numerical_features) + list(categorical_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46caa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importances\n",
    "# feature_importances = clf.feature_importances_\n",
    "feature_importances = clf.named_steps['classifier'].feature_importances_\n",
    "print(len(feature_importances))\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importances\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Visualize feature importances\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(feature_importances_df['feature'], feature_importances_df['importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importances')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "# Print the feature importances\n",
    "print(feature_importances_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f858a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_df\n",
    "feature_importances_df.to_csv(\"/output/decisiontree_feature_importance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4595e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_feature_importances_df = feature_importances_df.sort_values(['importance'], ascending=False).tail(100)\n",
    "pd.set_option('display.max_rows', None)\n",
    "top_100_feature_importances_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab0904e",
   "metadata": {},
   "source": [
    "**<h2>Insights</h2>**\n",
    "<li><b>Including all the feature columns</b></li>\n",
    "<li><b>Numerical feature columns and categorical columns were scaled using standardscaler and encoded using onehotencoder respectively</b></li>\n",
    "<li><b>Decision Tree Classifier is used to generate the feature importance</b></li>\n",
    "<li><b>Total 4941 features is created to fit into the model</b></li>\n",
    "<li><b>Out of all the features; amt, unix_time, merch_long, merch_lat, category, city_pop,lat,long,gender,merchant,job are some of the top features found</b></li>\n",
    "<li><b>Similarly, zip, street, first,last are some of the low ranking features found</b></li>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
