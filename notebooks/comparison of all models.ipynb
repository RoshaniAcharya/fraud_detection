{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import svm\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_knn(X_train, y_train, X_test, y_test):\n",
    "    print(\"----------KNN-----------\")\n",
    "    \n",
    "    param_grid = {'n_neighbors': np.arange(1, 20), 'weights': ['uniform', 'distance'], 'metric':[\"euclidean\", \"manhattan\", \"chebyshev\", \"minkowski\"]}\n",
    "    \n",
    "    clf = make_pipeline(\n",
    "        preprocessor,\n",
    "        SMOTE(sampling_strategy='minority', random_state=5),\n",
    "         KNeighborsClassifier()\n",
    "    )\n",
    "    \n",
    "    knn_gscv = GridSearchCV(clf, param_grid, cv=5)\n",
    "    knn_gscv.fit(X_train, y_train.values.ravel())\n",
    "    print(knn_gscv.best_params_, knn_gscv.best_score_)\n",
    "    y_pred = knn_gscv.predict(X_test)\n",
    "    print(f1_score(y_test, y_pred, average='weighted'))\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "    y_train_pred = knn_gscv.predict(X_train)\n",
    "#     print(classification_report(y_train, y_train_pred))\n",
    "    return {\n",
    "        \"f1_score\": f1_score(y_test, y_pred, average='weighted'),\n",
    "        \"params\" : knn_gscv.best_params_,\n",
    "        \"train_score\" : knn_gscv.best_score_,\n",
    "        \"test_score\" : accuracy_score(y_test, y_pred),\n",
    "        \"model\" : knn_gscv\n",
    "    }\n",
    "#     plot_confusion_matrix(knn_gscv, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rf(X_train, y_train, X_test, y_test):\n",
    "    print(\"----------RANDOM FOREST-----------\")\n",
    "    \n",
    "    parameters = {'n_estimators': [10,20,30,40,50,60,70,80,90,100], 'max_depth': [4,5,6,7,8], 'criterion': ['gini', 'entropy'], 'max_features': ['sqrt', 'log2']}\n",
    "\n",
    "        # Create a pipeline with preprocessing, SMOTE, and the Random Forest classifier\n",
    "    clf = make_pipeline(\n",
    "        preprocessor,\n",
    "        SMOTE(sampling_strategy='minority', random_state=5),\n",
    "        RandomForestClassifier(random_state=5)\n",
    "    )\n",
    "    \n",
    "    cv_combined = GridSearchCV(estimator=clf, param_grid=parameters, cv=5)\n",
    "    cv_combined.fit(X_train, y_train)\n",
    "\n",
    "    print('best params: ', cv_combined.best_params_)\n",
    "\n",
    "    y_pred = cv_combined.predict(X_test)\n",
    "    print(f1_score(y_test, y_pred, average='weighted'))\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "#     print(classification_report(y_train, cv_combined.predict(X_train)))\n",
    "    return {\n",
    "        \"f1_score\": f1_score(y_test, y_pred, average='weighted'),\n",
    "        \"params\" : cv_combined.best_params_,\n",
    "        \"train_score\" : cv_combined.best_score_,\n",
    "        \"test_score\" : accuracy_score(y_test, y_pred),\n",
    "        \"model\" : cv_combined\n",
    "    }\n",
    "#     plot_confusion_matrix(cv_combined, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dt(X_train, y_train, X_test, y_test, preprocessor):\n",
    "    print(\"----------DECISION TREE-----------\")\n",
    "\n",
    "    # Define the parameter grid for grid search\n",
    "    parameters = {\n",
    "        'decisiontreeclassifier__max_depth':  [4,5,6,7,8],\n",
    "        'decisiontreeclassifier__criterion': ['gini', 'entropy'],\n",
    "        'decisiontreeclassifier__max_features': ['sqrt', 'log2'],\n",
    "        'decisiontreeclassifier__min_samples_split': [2,6,10,14,18,22]\n",
    "    }\n",
    "    \n",
    "\n",
    "    # Create a pipeline with preprocessing, SMOTE, and the decision tree classifier\n",
    "    clf = make_pipeline(\n",
    "        preprocessor,\n",
    "        SMOTE(sampling_strategy='minority', random_state=5),\n",
    "        DecisionTreeClassifier(random_state=5)\n",
    "    )\n",
    "\n",
    "    # Initialize GridSearchCV with the pipeline and parameter grid\n",
    "    cv_combined = GridSearchCV(estimator=clf, param_grid=parameters, cv=5, refit=True, scoring=make_scorer(accuracy_score))\n",
    "    cv_combined.fit(X_train, y_train)\n",
    "\n",
    "    print('Best parameters: ', cv_combined.best_params_)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = cv_combined.predict(X_test)\n",
    "    \n",
    "    # Calculate and print the F1 score\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(f1)\n",
    "\n",
    "    # Return a dictionary with relevant metrics and the best model\n",
    "    return {\n",
    "        \"f1_score\": f1,\n",
    "        \"params\": cv_combined.best_params_,\n",
    "        \"train_score\": cv_combined.best_score_,\n",
    "        \"test_score\": accuracy_score(y_test, y_pred),\n",
    "        \"model\": cv_combined\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_svm(X_train, y_train, X_test, y_test):\n",
    "    print(\"----------SVM-----------\")\n",
    "    tuned_parameters = {'kernel': ['linear', 'rbf'], 'C': [1, 10, 100, 1000], 'gamma': [1e-3, 1e-4]}\n",
    "    \n",
    "    # Create a pipeline with preprocessing, SMOTE, and SVM\n",
    "    clf = make_pipeline(\n",
    "        preprocessor,\n",
    "        SMOTE(sampling_strategy='minority', random_state=5),\n",
    "        svm.SVC(random_state=10)\n",
    "    )\n",
    "\n",
    "\n",
    "    clf = GridSearchCV(clf, param_grid=tuned_parameters, cv=5)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(clf.best_params_)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(f1_score(y_test, y_pred, average='weighted'))\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "#     print(classification_report(y_train, clf.predict(X_train)))\n",
    "    return {\n",
    "        \"f1_score\": f1_score(y_test, y_pred, average='weighted'),\n",
    "        \"params\" : clf.best_params_,\n",
    "        \"train_score\" : clf.best_score_,\n",
    "        \"test_score\" : accuracy_score(y_test, y_pred)\n",
    "    }\n",
    "#     plot_confusion_matrix(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_log_dict(classifier, result):\n",
    "    row = {\n",
    "           \"classifier\": classifier,\n",
    "           \"params\": result[\"params\"],\n",
    "           \"f1_score\": result[\"f1_score\"],\n",
    "           \"train_score\": result[\"train_score\"],\n",
    "           \"test_score\": result[\"test_score\"]\n",
    "          }\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data():\n",
    "    numerical_features = ['amt','trans_month_sin', 'trans_month_cos', 'trans_hour_sin', 'trans_hour_cos','age','distance']\n",
    "    categorical_features = ['merchant', 'category','gender','city','state', 'job','trans_num']\n",
    "    numerical_transformer = StandardScaler()\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dt_grid_search_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_396313/2766169149.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mOUTPUT_FOLDER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dt_grid_search_result/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt_grid_search_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dt_grid_search_result' is not defined"
     ]
    }
   ],
   "source": [
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "# features_file = os.path.join(parent_dir, 'data', 'final_features.csv')\n",
    "# dataset = pd.read_csv(csv_file)\n",
    "\n",
    "output_list = []\n",
    "OUTPUT_FOLDER = os.path.join(parent_dir, 'output', 'dt_grid_search_result/')\n",
    "print(dt_grid_search_result)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(features_file)\n",
    "\n",
    "X = df.drop(columns=['is_fraud'])\n",
    "y = df['is_fraud']\n",
    "\n",
    "X_TRAIN, X_TEST, Y_TRAIN, Y_TEST = train_test_split(X,y,stratify=y,test_size = 0.2,random_state=42,shuffle=True)\n",
    "X_TRAIN.reset_index(drop=True,inplace=True)\n",
    "X_TEST.reset_index(drop=True,inplace=True)\n",
    "Y_TRAIN.reset_index(drop=True,inplace=True)\n",
    "Y_TEST.reset_index(drop=True,inplace=True)\n",
    "\n",
    "print(\"Distribution of y_train = {}\".format(Y_TRAIN.value_counts()))\n",
    "print(\"Distribution of y_test = {}\".format(Y_TEST.value_counts()))\n",
    "\n",
    "preprocessor = preprocess_data()\n",
    "\n",
    "dt_result = train_dt(X_TRAIN, Y_TRAIN, X_TEST, Y_TEST, preprocessor)\n",
    "# svm_result = train_svm(X_TRAIN, Y_TRAIN, X_TEST, preprocessor)\n",
    "# knn_result = train_knn(X_TRAIN, Y_TRAIN, X_TEST, preprocessor)\n",
    "# rf_result = train_rf(X_TRAIN, Y_TRAIN, X_TEST, preprocessor)\n",
    "\n",
    "\n",
    "dt_row = create_log_dict(\"decision_tree\", dt_result)\n",
    "# svm_row = create_log_dict( \"svm\", svm_result)\n",
    "# knn_row = create_log_dict(\"knn\", knn_result)\n",
    "# rf_row = create_log_dict(\"random_forest\", rf_result)\n",
    "\n",
    "output_list.append(dt_row)\n",
    "# output_list.append(svm_row)\n",
    "# output_list.append(knn_row)\n",
    "# output_list.append(rf_row)\n",
    "\n",
    "output_df = output_df.append(output_list)\n",
    "\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)\n",
    "with open(OUTPUT_FOLDER + f'results_first_exp_cv5.csv', 'a') as f:\n",
    "    output_df.to_csv(f, header=f.tell()==0, index=False)\n",
    "    joblib.dump(dt_result[\"model\"], OUTPUT_FOLDER + f'gridsearch_exp_dt_model.joblib')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = dt_result[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    257834\n",
      "           1       0.01      0.02      0.01      1501\n",
      "\n",
      "    accuracy                           0.99    259335\n",
      "   macro avg       0.50      0.51      0.50    259335\n",
      "weighted avg       0.99      0.99      0.99    259335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_TEST, clf.predict(X_TEST)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_confusion_matrix\u001b[49m(clf, X_TEST, Y_TEST)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "plot_confusion_matrix(clf, X_TEST, Y_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col, imp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[43mcols\u001b[49m, clf\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mfeature_importances_):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(col, imp)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cols' is not defined"
     ]
    }
   ],
   "source": [
    "for col, imp in zip(cols, clf.best_estimator_.feature_importances_):\n",
    "    print(col, imp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
