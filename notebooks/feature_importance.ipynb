{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "102f4fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_score, f1_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86a79063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                 int64\n",
      "trans_date_trans_time     object\n",
      "cc_num                     int64\n",
      "merchant                  object\n",
      "category                  object\n",
      "amt                      float64\n",
      "first                     object\n",
      "last                      object\n",
      "gender                    object\n",
      "street                    object\n",
      "city                      object\n",
      "state                     object\n",
      "zip                        int64\n",
      "lat                      float64\n",
      "long                     float64\n",
      "city_pop                   int64\n",
      "job                       object\n",
      "dob                       object\n",
      "trans_num                 object\n",
      "unix_time                  int64\n",
      "merch_lat                float64\n",
      "merch_long               float64\n",
      "is_fraud                   int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "csv_file = os.path.join(parent_dir, 'data', 'fraudTrain.csv')\n",
    "df = pd.read_csv(csv_file)\n",
    "df = df[:100]\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b400051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "# df['dob'] = pd.to_datetime(df['dob'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577e221d",
   "metadata": {},
   "source": [
    "**<h2>Training Decision Tree using the features to generate feature importance.</h2>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ca3466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data():\n",
    "#     numerical_features = ['amt', 'lat', 'long', 'city_pop', 'unix_time', 'merch_lat', 'merch_long','cc_num']\n",
    "#     categorical_features = ['merchant', 'category', 'first', 'last', 'gender', 'street', 'city', 'state', 'zip', 'job', 'trans_num']\n",
    "    numerical_features = ['amt','trans_month_sin', 'trans_month_cos', 'trans_hour_sin', 'trans_hour_cos','age','distance']\n",
    "    categorical_features = ['merchant', 'category','gender','city','state', 'job','trans_num']\n",
    "    numerical_transformer = StandardScaler()\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9594b553",
   "metadata": {},
   "source": [
    "<h2>Decision Tree</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b98e633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = df.drop('is_fraud', axis=1)\n",
    "y = df['is_fraud']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "preprocessor = preprocess_data()\n",
    "\n",
    "# Create the pipeline\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=10))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Save pipeline (including preprocessor and classifier) to a file\n",
    "# dump(clf, 'pipeline_with_model.joblib')\n",
    "\n",
    "print(\"here 3\")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74732c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(clf, X_test,y_test,cmap='Purples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578e8891",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(parent_dir, 'data', 'decisiontree_default_setup.joblib')\n",
    "\n",
    "joblib.dump(clf,model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d39080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of the numerical features\n",
    "numerical_features = ['amt', 'lat', 'long', 'city_pop', 'unix_time', 'merch_lat', 'merch_long']\n",
    "categorical_features = ['merchant', 'category','gender','city','state', 'job','trans_num']\n",
    "\n",
    "# Get the names of the categorical features after one-hot encoding\n",
    "categorical_transformer = clf.named_steps['preprocessor'].named_transformers_['cat']\n",
    "categorical_feature_names = categorical_transformer.get_feature_names_out(categorical_features)\n",
    "\n",
    "# Combine the names\n",
    "feature_names = list(numerical_features) + list(categorical_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46caa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importances\n",
    "# feature_importances = clf.feature_importances_\n",
    "feature_importances = clf.named_steps['classifier'].feature_importances_\n",
    "print(len(feature_importances))\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importances\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "# # Visualize feature importances\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.barh(feature_importances_df['feature'], feature_importances_df['importance'])\n",
    "# plt.xlabel('Importance')\n",
    "# plt.ylabel('Feature')\n",
    "# plt.title('Feature Importances')\n",
    "# plt.gca().invert_yaxis()\n",
    "# plt.show()\n",
    "\n",
    "# # Print the feature importances\n",
    "# print(feature_importances_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f858a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_path = os.path.join(parent_dir, 'data', 'dt-defeault_setup_ft_imp.csv')\n",
    "feature_importances_df.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4595e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_feature_importances_df = feature_importances_df.sort_values(['importance'], ascending=False).tail(100)\n",
    "pd.set_option('display.max_rows', None)\n",
    "top_100_feature_importances_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab0904e",
   "metadata": {},
   "source": [
    "**<h2>Insights</h2>**\n",
    "<li><b>Including all the feature columns</b></li>\n",
    "<li><b>Numerical feature columns and categorical columns were scaled using standardscaler and encoded using onehotencoder respectively</b></li>\n",
    "<li><b>Decision Tree is used to generate the feature importance</b></li>\n",
    "<li><b>Total 4941 features is created to fit into the model</b></li>\n",
    "<li><b>Out of all the features; amt, unix_time, merch_long, merch_lat, category, city_pop,lat,long,gender,merchant,job are some of the top features found</b></li>\n",
    "<li><b>Similarly, zip, street, first,last are some of the low ranking features found</b></li>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
